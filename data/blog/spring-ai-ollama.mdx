---
title: Spring AI 和 Ollama
date: 2024-04-21 19:20:01
tags: ['SpringBoot', 'AI']
draft: false
authors: ['default']
---

## 概述
Spring AI 不仅提供了与 OpenAI 进行API交互，同样支持与 Ollama 进行API交互。[Ollama](https://github.com/jmorganca/ollama) 是一个发布在GitHub上的项目，专为运行、创建和分享大型语言模型而设计，可以轻松地在本地启动和运行大型语言模型。


## Docker环境安装Ollama
1.获取Docker镜像。
```sh
docker pull ollama/ollama
```

2.在 Docker 容器内运行 Ollama。
```sh
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
```

3.现在您可以在容器内运行像 Llama 2 这样的模型。

```sh
docker exec -it ollama ollama run llama2
```
[更多模型可以在Ollama 库](https://ollama.ai/library) 中找到。

## 创建 Spring Boot 项目

首先引入相关依赖。
```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
        <version>3.2.0</version>
    </dependency>

    <dependency>
        <groupId>org.springframework.ai</groupId>
        <artifactId>spring-ai-ollama</artifactId>
        <version>0.8.0-SNAPSHOT</version>
    </dependency>
</dependencies>

<repositories>
    <repository>
        <id>spring-snapshots</id>
        <name>Spring Snapshots</name>
        <url>https://repo.spring.io/snapshot</url>
        <releases>
            <enabled>false</enabled>
        </releases>
    </repository>
</repositories>

```

在 application.yml 中配置 Ollama 地址和使用的模型。

```yml
spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      embedding:
        model: llama2
```


这里我们填写一个提示来测试下，`ChatClient`将调用Ollama的API接口。

```java
@GetMapping("/top/fiction")
public String topCodeLanguage() {
    String message = "2023最受欢迎小说是什么";
    return chatClient.generate(message);
}
```

我们稍微对上面的接口做些更改，我首先将一个路径变量放入请求，这样我们就可以将年份模板化。`PromptTemplate`旨在帮助创建结构化提示，我们通过add()方法插入动态内容，render()会渲染为最终字符串格式。

```java
@GetMapping("/top/fiction/{year}")
public String topCodeLanguageByYear(@PathVariable("year") Integer year) {
    String message = "{year}最受欢迎小说是什么";
    PromptTemplate promptTemplate = new PromptTemplate(message);
    promptTemplate.add("year", year);
    return chatClient.generate(promptTemplate.render());
}
```


## 结论

我们已经完成了Spring AI 与Ollama的基本示例，与往常一样，本文中使用的源代码可 [在 GitHub 上](https://github.com/ReLive27/spring-boot-sample/tree/main/spring-ai) 获得。
